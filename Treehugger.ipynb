{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "enclosed-mozambique",
   "metadata": {},
   "source": [
    "## Neural networks project\n",
    "\n",
    "#### This is a datascience training project in which I had to create a neural network to predict the kind of trees will grow in an area based on cartographic data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-blind",
   "metadata": {},
   "source": [
    "### 1st I loaded the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "official-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import  Dense, Dropout\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-franklin",
   "metadata": {},
   "source": [
    "### Then I loaded and inspected the data, as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hawaiian-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"cover_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "anonymous-watson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  class  \n",
       "0            0            0      5  \n",
       "1            0            0      5  \n",
       "2            0            0      2  \n",
       "3            0            0      2  \n",
       "4            0            0      5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-serum",
   "metadata": {},
   "source": [
    "### To avoid writing all the features one-by-one, this command gives me a list of columns, I'll just need to remove the last one that gives the tree-cover type, which is what we are training the algorithm to predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fabulous-fusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
       "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
       "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
       "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
       "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
       "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
       "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
       "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
       "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
       "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
       "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
       "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
       "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
       "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
       "       'Soil_Type39', 'Soil_Type40', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-spiritual",
   "metadata": {},
   "source": [
    "### This command gets me a list of all the cartographic data into a dataframe, this is going to be our input in the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "published-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
    "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
    "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
    "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
    "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
    "       'Soil_Type6', 'Soil_Type7', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10',\n",
    "       'Soil_Type11', 'Soil_Type12', 'Soil_Type13', 'Soil_Type14',\n",
    "       'Soil_Type15', 'Soil_Type16', 'Soil_Type17', 'Soil_Type18',\n",
    "       'Soil_Type19', 'Soil_Type20', 'Soil_Type21', 'Soil_Type22',\n",
    "       'Soil_Type23', 'Soil_Type24', 'Soil_Type25', 'Soil_Type26',\n",
    "       'Soil_Type27', 'Soil_Type28', 'Soil_Type29', 'Soil_Type30',\n",
    "       'Soil_Type31', 'Soil_Type32', 'Soil_Type33', 'Soil_Type34',\n",
    "       'Soil_Type35', 'Soil_Type36', 'Soil_Type37', 'Soil_Type38',\n",
    "       'Soil_Type39', 'Soil_Type40']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-tennessee",
   "metadata": {},
   "source": [
    "### I also need to create a dataframe with the labels, which is what we want to predict with the algorythm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "german-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data[\"class\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-validity",
   "metadata": {},
   "source": [
    "### Looking at the shape of the labels, it seems that type 1 and type 2 treecovers are the most abundant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "imposed-meaning",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    283301\n",
       "1    211840\n",
       "3     35754\n",
       "7     20510\n",
       "6     17367\n",
       "5      9493\n",
       "4      2747\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-gauge",
   "metadata": {},
   "source": [
    "### In most machine learning models, including neural networks, we usually start by dividing the data into a training set and a testing set. \n",
    "\n",
    "### Like the name indicates, the training set is used to train the neural network, and the test set is used to evaluate it's accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "representative-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-balance",
   "metadata": {},
   "source": [
    "### Before we start, we need to make sure that the data is normalized, we don't want any input to have disproportionate weight. We'll normalize it in a way that it's average becomes 0 and std deviation becomes 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ahead-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = StandardScaler()\n",
    "x_train = ct.fit_transform(x_train)\n",
    "x_test = ct.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-collection",
   "metadata": {},
   "source": [
    "### Now we are ready to create the neural network, we start by chosing which kind of model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "southern-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-bracket",
   "metadata": {},
   "source": [
    "### We create the imput layer, which corresponds to the number of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "crude-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.InputLayer(input_shape=(54,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-helena",
   "metadata": {},
   "source": [
    "### Then we build a brain, this is the customizable step, and where the name deep learning comes from, we can decide how deep the brain is, and how many neurons it contains, balancing the accuracy of the model and the time it takes to compute.\n",
    "\n",
    "### After some configuration attempts, this is the brain architecture I came up with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "applicable-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(356, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-rhythm",
   "metadata": {},
   "source": [
    "### We create a script to train the neural network, with the parameters we are optimizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "alert-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-madonna",
   "metadata": {},
   "source": [
    "### And we input our training data, with 100 epochs the accuracy of the model is 93%. You can reduced the number of epochs if you are in a hurry, althought the accuracy won't be as good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "upper-creature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "88/88 [==============================] - 5s 47ms/step - loss: 0.8234 - sparse_categorical_accuracy: 0.6852\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 4s 46ms/step - loss: 0.5769 - sparse_categorical_accuracy: 0.7560\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 4s 45ms/step - loss: 0.5223 - sparse_categorical_accuracy: 0.7779\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 0.4865 - sparse_categorical_accuracy: 0.7935\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 4s 43ms/step - loss: 0.4570 - sparse_categorical_accuracy: 0.8076\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 4s 44ms/step - loss: 0.4335 - sparse_categorical_accuracy: 0.8194\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 4s 44ms/step - loss: 0.4157 - sparse_categorical_accuracy: 0.8273\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 4s 43ms/step - loss: 0.3983 - sparse_categorical_accuracy: 0.8353\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 4s 42ms/step - loss: 0.3889 - sparse_categorical_accuracy: 0.8390\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.8472\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 4s 43ms/step - loss: 0.3628 - sparse_categorical_accuracy: 0.8509\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 4s 42ms/step - loss: 0.3524 - sparse_categorical_accuracy: 0.8558\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 4s 42ms/step - loss: 0.3421 - sparse_categorical_accuracy: 0.8608\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 0.3338 - sparse_categorical_accuracy: 0.8645\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 4s 46ms/step - loss: 0.3304 - sparse_categorical_accuracy: 0.8654\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 4s 42ms/step - loss: 0.3206 - sparse_categorical_accuracy: 0.8702\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 4s 44ms/step - loss: 0.3182 - sparse_categorical_accuracy: 0.8710\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 4s 48ms/step - loss: 0.3087 - sparse_categorical_accuracy: 0.8752\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 5s 52ms/step - loss: 0.3024 - sparse_categorical_accuracy: 0.8775\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 0.2985 - sparse_categorical_accuracy: 0.8799\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 0.2939 - sparse_categorical_accuracy: 0.8812\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 6s 71ms/step - loss: 0.2864 - sparse_categorical_accuracy: 0.8846\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 7s 80ms/step - loss: 0.2849 - sparse_categorical_accuracy: 0.8853\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 5s 55ms/step - loss: 0.2815 - sparse_categorical_accuracy: 0.8863\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 5s 56ms/step - loss: 0.2771 - sparse_categorical_accuracy: 0.8886\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 0.2703 - sparse_categorical_accuracy: 0.8912\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 5s 54ms/step - loss: 0.2733 - sparse_categorical_accuracy: 0.8895\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 4s 46ms/step - loss: 0.2629 - sparse_categorical_accuracy: 0.8948\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 4s 47ms/step - loss: 0.2639 - sparse_categorical_accuracy: 0.8942\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 0.2588 - sparse_categorical_accuracy: 0.8963\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 4s 50ms/step - loss: 0.2548 - sparse_categorical_accuracy: 0.8979\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 4s 43ms/step - loss: 0.2513 - sparse_categorical_accuracy: 0.8997\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 0.2497 - sparse_categorical_accuracy: 0.9003\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 4s 48ms/step - loss: 0.2474 - sparse_categorical_accuracy: 0.9013\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 4s 48ms/step - loss: 0.2450 - sparse_categorical_accuracy: 0.9023\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 4s 46ms/step - loss: 0.2421 - sparse_categorical_accuracy: 0.9036\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 4s 45ms/step - loss: 0.2384 - sparse_categorical_accuracy: 0.9049\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - 4s 48ms/step - loss: 0.2398 - sparse_categorical_accuracy: 0.9041\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - 4s 51ms/step - loss: 0.2425 - sparse_categorical_accuracy: 0.9024\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - 4s 45ms/step - loss: 0.2312 - sparse_categorical_accuracy: 0.9080\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 0.2297 - sparse_categorical_accuracy: 0.9090\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - 3s 40ms/step - loss: 0.2279 - sparse_categorical_accuracy: 0.9096\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 0.2259 - sparse_categorical_accuracy: 0.9108\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 0.2275 - sparse_categorical_accuracy: 0.9095\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 0.2249 - sparse_categorical_accuracy: 0.9110\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - 4s 43ms/step - loss: 0.2199 - sparse_categorical_accuracy: 0.9126\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - 3s 39ms/step - loss: 0.2189 - sparse_categorical_accuracy: 0.9130\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - 3s 39ms/step - loss: 0.2163 - sparse_categorical_accuracy: 0.9144\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.2156 - sparse_categorical_accuracy: 0.9150\n",
      "Epoch 50/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.2152 - sparse_categorical_accuracy: 0.9153\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - 3s 37ms/step - loss: 0.2152 - sparse_categorical_accuracy: 0.9144\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - 3s 39ms/step - loss: 0.2157 - sparse_categorical_accuracy: 0.9138\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.2087 - sparse_categorical_accuracy: 0.9178\n",
      "Epoch 54/100\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 0.2070 - sparse_categorical_accuracy: 0.9184\n",
      "Epoch 55/100\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 0.2101 - sparse_categorical_accuracy: 0.9162\n",
      "Epoch 56/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.2087 - sparse_categorical_accuracy: 0.9172\n",
      "Epoch 57/100\n",
      "88/88 [==============================] - 3s 39ms/step - loss: 0.2043 - sparse_categorical_accuracy: 0.9194\n",
      "Epoch 58/100\n",
      "88/88 [==============================] - 3s 40ms/step - loss: 0.2051 - sparse_categorical_accuracy: 0.9186\n",
      "Epoch 59/100\n",
      "88/88 [==============================] - 3s 37ms/step - loss: 0.2051 - sparse_categorical_accuracy: 0.9186\n",
      "Epoch 60/100\n",
      "88/88 [==============================] - 3s 39ms/step - loss: 0.2057 - sparse_categorical_accuracy: 0.9185\n",
      "Epoch 61/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.1966 - sparse_categorical_accuracy: 0.9228\n",
      "Epoch 62/100\n",
      "88/88 [==============================] - 3s 39ms/step - loss: 0.1962 - sparse_categorical_accuracy: 0.9228\n",
      "Epoch 63/100\n",
      "88/88 [==============================] - 3s 39ms/step - loss: 0.1996 - sparse_categorical_accuracy: 0.9211\n",
      "Epoch 64/100\n",
      "88/88 [==============================] - 4s 43ms/step - loss: 0.1969 - sparse_categorical_accuracy: 0.9224\n",
      "Epoch 65/100\n",
      "88/88 [==============================] - 4s 43ms/step - loss: 0.1965 - sparse_categorical_accuracy: 0.9222\n",
      "Epoch 66/100\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 0.1923 - sparse_categorical_accuracy: 0.9243\n",
      "Epoch 67/100\n",
      "88/88 [==============================] - 3s 39ms/step - loss: 0.1926 - sparse_categorical_accuracy: 0.9240\n",
      "Epoch 68/100\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 0.1978 - sparse_categorical_accuracy: 0.9215\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 3s 39ms/step - loss: 0.1947 - sparse_categorical_accuracy: 0.9230\n",
      "Epoch 70/100\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 0.1992 - sparse_categorical_accuracy: 0.9205\n",
      "Epoch 71/100\n",
      "88/88 [==============================] - 4s 42ms/step - loss: 0.1873 - sparse_categorical_accuracy: 0.9262\n",
      "Epoch 72/100\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 0.1874 - sparse_categorical_accuracy: 0.9260\n",
      "Epoch 73/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.1845 - sparse_categorical_accuracy: 0.9280\n",
      "Epoch 74/100\n",
      "88/88 [==============================] - 3s 39ms/step - loss: 0.1858 - sparse_categorical_accuracy: 0.9271\n",
      "Epoch 75/100\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 0.1876 - sparse_categorical_accuracy: 0.9262\n",
      "Epoch 76/100\n",
      "88/88 [==============================] - 4s 46ms/step - loss: 0.1878 - sparse_categorical_accuracy: 0.9258\n",
      "Epoch 77/100\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 0.1875 - sparse_categorical_accuracy: 0.9262\n",
      "Epoch 78/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.1868 - sparse_categorical_accuracy: 0.9260\n",
      "Epoch 79/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.1814 - sparse_categorical_accuracy: 0.9289\n",
      "Epoch 80/100\n",
      "88/88 [==============================] - 3s 37ms/step - loss: 0.1798 - sparse_categorical_accuracy: 0.9296\n",
      "Epoch 81/100\n",
      "88/88 [==============================] - 3s 37ms/step - loss: 0.1822 - sparse_categorical_accuracy: 0.9282\n",
      "Epoch 82/100\n",
      "88/88 [==============================] - 3s 37ms/step - loss: 0.1825 - sparse_categorical_accuracy: 0.9281\n",
      "Epoch 83/100\n",
      "88/88 [==============================] - 3s 37ms/step - loss: 0.1800 - sparse_categorical_accuracy: 0.9290\n",
      "Epoch 84/100\n",
      "88/88 [==============================] - 3s 40ms/step - loss: 0.1840 - sparse_categorical_accuracy: 0.9266\n",
      "Epoch 85/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.1785 - sparse_categorical_accuracy: 0.9298\n",
      "Epoch 86/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.1763 - sparse_categorical_accuracy: 0.9304\n",
      "Epoch 87/100\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 0.1782 - sparse_categorical_accuracy: 0.9297\n",
      "Epoch 88/100\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 0.1762 - sparse_categorical_accuracy: 0.9304\n",
      "Epoch 89/100\n",
      "88/88 [==============================] - 4s 51ms/step - loss: 0.1746 - sparse_categorical_accuracy: 0.9315\n",
      "Epoch 90/100\n",
      "88/88 [==============================] - 3s 39ms/step - loss: 0.1740 - sparse_categorical_accuracy: 0.9313\n",
      "Epoch 91/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.1735 - sparse_categorical_accuracy: 0.9317\n",
      "Epoch 92/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.1741 - sparse_categorical_accuracy: 0.9312\n",
      "Epoch 93/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.1706 - sparse_categorical_accuracy: 0.9331\n",
      "Epoch 94/100\n",
      "88/88 [==============================] - 3s 37ms/step - loss: 0.1757 - sparse_categorical_accuracy: 0.9303\n",
      "Epoch 95/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.1735 - sparse_categorical_accuracy: 0.9320\n",
      "Epoch 96/100\n",
      "88/88 [==============================] - 3s 37ms/step - loss: 0.1732 - sparse_categorical_accuracy: 0.9315\n",
      "Epoch 97/100\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 0.1736 - sparse_categorical_accuracy: 0.9314\n",
      "Epoch 98/100\n",
      "88/88 [==============================] - 3s 38ms/step - loss: 0.1699 - sparse_categorical_accuracy: 0.9330\n",
      "Epoch 99/100\n",
      "88/88 [==============================] - 3s 37ms/step - loss: 0.1706 - sparse_categorical_accuracy: 0.9328\n",
      "Epoch 100/100\n",
      "88/88 [==============================] - 3s 37ms/step - loss: 0.1668 - sparse_categorical_accuracy: 0.9344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23b862903d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 100, batch_size = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-corporation",
   "metadata": {},
   "source": [
    "### And we test the model on our validation data, getting a final report about the performance of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "relevant-checkout",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4540/4540 [==============================] - 7s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.87      0.91     52978\n",
      "           2       0.90      0.96      0.93     70810\n",
      "           3       0.87      0.95      0.91      8975\n",
      "           4       0.85      0.81      0.83       690\n",
      "           5       0.80      0.79      0.80      2308\n",
      "           6       0.91      0.73      0.81      4386\n",
      "           7       0.93      0.94      0.94      5106\n",
      "\n",
      "    accuracy                           0.92    145253\n",
      "   macro avg       0.89      0.87      0.88    145253\n",
      "weighted avg       0.92      0.92      0.92    145253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_estimate = model.predict(x_test)\n",
    "y_estimate = np.argmax(y_estimate, axis = 1)\n",
    "print(classification_report(y_test, y_estimate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-disney",
   "metadata": {},
   "source": [
    "### Final comment: neural networks have the advantage of being very efficient at classifing data, but they have the problem of being \"blackboxes\", in which it is almost impossible to get insight on what is the weight of each input to the final prediction.\n",
    "\n",
    "### Usually, when trying to understand the why is more important than the final classification, using other machine learning methods is more appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
